{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "responsible-filename",
   "metadata": {},
   "source": [
    "# Create a model using the lgbm_02_02 hyperparameters\n",
    "\n",
    "But without using any scaling. Submit this to the competition to check I am comparing apples with apples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-samba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:44:31.567194Z",
     "start_time": "2021-02-15T14:44:30.265955Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMClassifier\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV \n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "############ USE FOR GOOGLE COLAB ############\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/Earthquake_damage/data')\n",
    "# SUBMISSIONS_DIR = Path('drive/MyDrive/Work/Delivery/Current/Earthquake_damage/submissions')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/Earthquake_damage/models')\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#############################################\n",
    "\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DATA_DIR = Path('../download')\n",
    "SUBMISSIONS_DIR = Path('../submissions')\n",
    "MODEL_DIR = Path('../models')\n",
    "#######################################\n",
    "\n",
    "# The code runs the same if working on Jupyter or Colab, just need to change the \n",
    "# dirs above\n",
    "\n",
    "X = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "bool_columns = [col for col in X.columns if col.startswith('has')]\n",
    "X[categorical_columns] = X[categorical_columns].astype('category')\n",
    "X[bool_columns] = X[bool_columns].astype('bool')\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "y = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-blond",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:44:41.612156Z",
     "start_time": "2021-02-15T14:44:41.608753Z"
    }
   },
   "outputs": [],
   "source": [
    "top_14_features = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', \n",
    "                    'count_floors_pre_eq', 'age'\t, 'area_percentage'\t, \n",
    "                    'height_percentage', \n",
    "                    'has_superstructure_mud_mortar_stone',\n",
    "                    'has_superstructure_stone_flag', \n",
    "                    'has_superstructure_mud_mortar_brick',\n",
    "                    'has_superstructure_cement_mortar_brick',\n",
    "                    'has_superstructure_timber', 'count_families',\n",
    "                    'other_floor_type_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternative-milton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:45:35.716528Z",
     "start_time": "2021-02-15T14:45:35.713050Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(boosting_type='goss',\n",
    "                       learning_rate=0.2,\n",
    "                       min_child_samples=40,\n",
    "                       n_estimators=240,\n",
    "                       num_leaves=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spanish-morocco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:45:51.433365Z",
     "start_time": "2021-02-15T14:45:42.483766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', learning_rate=0.2, min_child_samples=40,\n",
       "               n_estimators=240, num_leaves=120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[top_14_features], np.ravel(y), verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "floating-contemporary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:56:50.193837Z",
     "start_time": "2021-02-15T14:56:50.187423Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_submission_top_14_features(pipeline, title):\n",
    "    \"\"\"\n",
    "    Given a trained pipeline object, use it to make predictions on the \n",
    "    submission test set 'test_values.csv' and write them a csv in the submissions\n",
    "    folder.\n",
    "    \"\"\"\n",
    "    # Read in test_values csv and apply data preprocessing\n",
    "    # note: will create a data preprocessing pipeline or function in future\n",
    "    test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')\n",
    "    test_values[categorical_columns] = test_values[categorical_columns].astype('category')\n",
    "    test_values[bool_columns] = test_values[bool_columns].astype('bool')\n",
    "    test_values = pd.get_dummies(test_values)\n",
    "    test_values = test_values[top_14_features]\n",
    "\n",
    "    # Generate predictions using pipeline we pass in\n",
    "    predictions = pipeline.predict(test_values)\n",
    "\n",
    "    submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv',\n",
    "                                    index_col='building_id')\n",
    "\n",
    "    my_submission = pd.DataFrame(data=predictions,\n",
    "                                columns=submission_format.columns,\n",
    "                                index=submission_format.index)\n",
    "    \n",
    "    my_submission.to_csv(SUBMISSIONS_DIR / f'{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "standard-genetics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:56:55.974181Z",
     "start_time": "2021-02-15T14:56:53.755297Z"
    }
   },
   "outputs": [],
   "source": [
    "make_submission_top_14_features(model, '02-15 - LightGBM - lgbm_02_02 params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "structured-hungary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:57:11.292513Z",
     "start_time": "2021-02-15T14:57:06.597712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875104086323538"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X[top_14_features])\n",
    "f1_score(y, y_pred, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
