{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "environmental-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path(\"../download\")\n",
    "DATA_DIR = Path(\"../data\")\n",
    "SUBMISSIONS_DIR = Path(\"../submissions\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / \"train_values.csv\", index_col=\"building_id\")\n",
    "categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "bool_columns = [col for col in X.columns if col.startswith(\"has\")]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / \"test_values.csv\", index_col=\"building_id\")\n",
    "y = pd.read_csv(DOWNLOAD_DIR / \"train_labels.csv\", index_col=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpine-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "negative-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">jumping-resonance-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/2xrnubhb\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/2xrnubhb</a><br/>\n",
       "                Run data is saved locally in <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210315_172413-2xrnubhb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"earthquake_damage_competition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "german-moldova",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86868, 38)"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "northern-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "t = [(\"ord_encoder\", OrdinalEncoder(dtype=int), categorical_columns)]\n",
    "ct = ColumnTransformer(transformers=t, remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bored-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_ints = ct.fit_transform(X)\n",
    "y = label_enc.fit_transform(np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hydraulic-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that append for pandas objects works differently to append with\n",
    "# python objects e.g. python append modifes the list in-place\n",
    "# pandas append returns a new object, leaving the original unmodified\n",
    "not_categorical_columns = X.select_dtypes(exclude=\"object\").columns\n",
    "cols_ordered_after_ordinal_encoding = categorical_columns.append(\n",
    "    not_categorical_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southern-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = pd.Index([\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"])\n",
    "cat_cols_plus_geo = categorical_columns.append(geo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interior-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_all_ints,\n",
    "    label=y,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prescription-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the docs for lgb.train and lgb.cv\n",
    "# Helpful Stackoverflow answer:\n",
    "# https://stackoverflow.com/questions/50931168/f1-score-metric-in-lightgbm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def get_ith_pred(preds, i, num_data, num_class):\n",
    "    \"\"\"\n",
    "    preds: 1D NumPY array\n",
    "        A 1D numpy array containing predicted probabilities. Has shape\n",
    "        (num_data * num_class,). So, For binary classification with\n",
    "        100 rows of data in your training set, preds is shape (200,),\n",
    "        i.e. (100 * 2,).\n",
    "    i: int\n",
    "        The row/sample in your training data you wish to calculate\n",
    "        the prediction for.\n",
    "    num_data: int\n",
    "        The number of rows/samples in your training data\n",
    "    num_class: int\n",
    "        The number of classes in your classification task.\n",
    "        Must be greater than 2.\n",
    "\n",
    "\n",
    "    LightGBM docs tell us that to get the probability of class 0 for\n",
    "    the 5th row of the dataset we do preds[0 * num_data + 5].\n",
    "    For class 1 prediction of 7th row, do preds[1 * num_data + 7].\n",
    "\n",
    "    sklearn's f1_score(y_true, y_pred) expects y_pred to be of the form\n",
    "    [0, 1, 1, 1, 1, 0...] and not probabilities.\n",
    "\n",
    "    This function translates preds into the form sklearn's f1_score\n",
    "    understands.\n",
    "    \"\"\"\n",
    "    # Does not work for binary classification, preds has a different form\n",
    "    # in that case\n",
    "    assert num_class > 2\n",
    "\n",
    "    preds_for_ith_row = [\n",
    "        preds[class_label * num_data + i] for class_label in range(num_class)\n",
    "    ]\n",
    "\n",
    "    # The element with the highest probability is predicted\n",
    "    return np.argmax(preds_for_ith_row)\n",
    "\n",
    "\n",
    "def lgb_f1_micro(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "\n",
    "    num_data = len(y_true)\n",
    "    num_class = 3\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(num_data):\n",
    "        ith_pred = get_ith_pred(preds, i, num_data, num_class)\n",
    "        y_pred.append(ith_pred)\n",
    "\n",
    "    return \"f1\", f1_score(y_true, y_pred, average=\"micro\"), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inclusive-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
