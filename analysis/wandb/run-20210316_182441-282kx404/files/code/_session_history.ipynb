{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resistant-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path('../download')\n",
    "DATA_DIR = Path('../data')\n",
    "SUBMISSIONS_DIR = Path('../submissions')\n",
    "MODEL_DIR = Path('../models')\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / 'train_values.csv', index_col='building_id')\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "bool_columns = [col for col in X.columns if col.startswith('has')]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / 'test_values.csv', index_col='building_id')\n",
    "y = pd.read_csv(DOWNLOAD_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "balanced-wesley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "based-enzyme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86868, 38)"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "t = [('ord_encoder', OrdinalEncoder(dtype=int), categorical_columns)]\n",
    "ct = ColumnTransformer(transformers=t, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "billion-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_ints = ct.fit_transform(X)\n",
    "y = label_enc.fit_transform(np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "material-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that append for pandas objects works differently to append with\n",
    "# python objects e.g. python append modifes the list in-place\n",
    "# pandas append returns a new object, leaving the original unmodified\n",
    "not_categorical_columns = X.select_dtypes(exclude='object').columns\n",
    "cols_ordered_after_ordinal_encoding = categorical_columns.append(not_categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limited-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = pd.Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'])\n",
    "cat_cols_plus_geo = categorical_columns.append(geo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "domestic-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_all_ints,\n",
    "                        label=y,\n",
    "                        feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "                        categorical_feature=list(cat_cols_plus_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "magnetic-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the docs for lgb.train and lgb.cv\n",
    "# Helpful Stackoverflow answer: \n",
    "# https://stackoverflow.com/questions/50931168/f1-score-metric-in-lightgbm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_ith_pred(preds, i, num_data, num_class):\n",
    "    \"\"\"\n",
    "    preds: 1D NumPY array\n",
    "        A 1D numpy array containing predicted probabilities. Has shape\n",
    "        (num_data * num_class,). So, For binary classification with \n",
    "        100 rows of data in your training set, preds is shape (200,), \n",
    "        i.e. (100 * 2,).\n",
    "    i: int\n",
    "        The row/sample in your training data you wish to calculate\n",
    "        the prediction for.\n",
    "    num_data: int\n",
    "        The number of rows/samples in your training data\n",
    "    num_class: int\n",
    "        The number of classes in your classification task.\n",
    "        Must be greater than 2.\n",
    "    \n",
    "    \n",
    "    LightGBM docs tell us that to get the probability of class 0 for \n",
    "    the 5th row of the dataset we do preds[0 * num_data + 5].\n",
    "    For class 1 prediction of 7th row, do preds[1 * num_data + 7].\n",
    "    \n",
    "    sklearn's f1_score(y_true, y_pred) expects y_pred to be of the form\n",
    "    [0, 1, 1, 1, 1, 0...] and not probabilities.\n",
    "    \n",
    "    This function translates preds into the form sklearn's f1_score \n",
    "    understands.\n",
    "    \"\"\"\n",
    "    # Does not work for binary classification, preds has a different form\n",
    "    # in that case\n",
    "    assert num_class > 2\n",
    "    \n",
    "    preds_for_ith_row = [preds[class_label * num_data + i]\n",
    "                        for class_label in range(num_class)]\n",
    "    \n",
    "    # The element with the highest probability is predicted\n",
    "    return np.argmax(preds_for_ith_row)\n",
    "    \n",
    "def lgb_f1_micro(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    \n",
    "    num_data = len(y_true)\n",
    "    num_class = 3\n",
    "    \n",
    "    y_pred = []\n",
    "    for i in range(num_data):\n",
    "        ith_pred = get_ith_pred(preds, i, num_data, num_class)\n",
    "        y_pred.append(ith_pred)\n",
    "    \n",
    "    return 'f1', f1_score(y_true, y_pred, average='micro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "everyday-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path('../download')\n",
    "DATA_DIR = Path('../data')\n",
    "SUBMISSIONS_DIR = Path('../submissions')\n",
    "MODEL_DIR = Path('../models')\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / 'train_values.csv', index_col='building_id')\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "bool_columns = [col for col in X.columns if col.startswith('has')]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / 'test_values.csv', index_col='building_id')\n",
    "y = pd.read_csv(DOWNLOAD_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inside-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path('../download')\n",
    "DATA_DIR = Path('../data')\n",
    "SUBMISSIONS_DIR = Path('../submissions')\n",
    "MODEL_DIR = Path('../models')\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / 'train_values.csv', index_col='building_id')\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "bool_columns = [col for col in X.columns if col.startswith('has')]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / 'test_values.csv', index_col='building_id')\n",
    "y = pd.read_csv(DOWNLOAD_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "available-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solved-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "t = [('ord_encoder', OrdinalEncoder(dtype=int), categorical_columns)]\n",
    "ct = ColumnTransformer(transformers=t, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hidden-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_ints = ct.fit_transform(X)\n",
    "y = label_enc.fit_transform(np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "useful-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that append for pandas objects works differently to append with\n",
    "# python objects e.g. python append modifes the list in-place\n",
    "# pandas append returns a new object, leaving the original unmodified\n",
    "not_categorical_columns = X.select_dtypes(exclude='object').columns\n",
    "cols_ordered_after_ordinal_encoding = categorical_columns.append(not_categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "discrete-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = pd.Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'])\n",
    "cat_cols_plus_geo = categorical_columns.append(geo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dirty-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_all_ints,\n",
    "                        label=y,\n",
    "                        feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "                        categorical_feature=list(cat_cols_plus_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "considered-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the docs for lgb.train and lgb.cv\n",
    "# Helpful Stackoverflow answer: \n",
    "# https://stackoverflow.com/questions/50931168/f1-score-metric-in-lightgbm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_ith_pred(preds, i, num_data, num_class):\n",
    "    \"\"\"\n",
    "    preds: 1D NumPY array\n",
    "        A 1D numpy array containing predicted probabilities. Has shape\n",
    "        (num_data * num_class,). So, For binary classification with \n",
    "        100 rows of data in your training set, preds is shape (200,), \n",
    "        i.e. (100 * 2,).\n",
    "    i: int\n",
    "        The row/sample in your training data you wish to calculate\n",
    "        the prediction for.\n",
    "    num_data: int\n",
    "        The number of rows/samples in your training data\n",
    "    num_class: int\n",
    "        The number of classes in your classification task.\n",
    "        Must be greater than 2.\n",
    "    \n",
    "    \n",
    "    LightGBM docs tell us that to get the probability of class 0 for \n",
    "    the 5th row of the dataset we do preds[0 * num_data + 5].\n",
    "    For class 1 prediction of 7th row, do preds[1 * num_data + 7].\n",
    "    \n",
    "    sklearn's f1_score(y_true, y_pred) expects y_pred to be of the form\n",
    "    [0, 1, 1, 1, 1, 0...] and not probabilities.\n",
    "    \n",
    "    This function translates preds into the form sklearn's f1_score \n",
    "    understands.\n",
    "    \"\"\"\n",
    "    # Does not work for binary classification, preds has a different form\n",
    "    # in that case\n",
    "    assert num_class > 2\n",
    "    \n",
    "    preds_for_ith_row = [preds[class_label * num_data + i]\n",
    "                        for class_label in range(num_class)]\n",
    "    \n",
    "    # The element with the highest probability is predicted\n",
    "    return np.argmax(preds_for_ith_row)\n",
    "    \n",
    "def lgb_f1_micro(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    \n",
    "    num_data = len(y_true)\n",
    "    num_class = 3\n",
    "    \n",
    "    y_pred = []\n",
    "    for i in range(num_data):\n",
    "        ith_pred = get_ith_pred(preds, i, num_data, num_class)\n",
    "        y_pred.append(ith_pred)\n",
    "    \n",
    "    return 'f1', f1_score(y_true, y_pred, average='micro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "heated-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx))\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y\n",
    "                                                       train_idx, val_idx)\n",
    "    bagged_preds = np.zeroes(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hairy-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx))\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    bagged_preds = np.zeroes(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "champion-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx))\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    bagged_preds = np.zeros(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "original-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx), val_idx.shape)\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    bagged_preds = np.zeros(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "obvious-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx), val_idx.shape)\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    # Perform bagged model building and evaluation to get a score\n",
    "    print(val_dataset.num_data())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "correct-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
    "    train_dataset.construct()\n",
    "    val_dataset.construct()\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def eval_bagged_model(config, num_bags, train_dataset, val_dataset):\n",
    "    bagged_preds = np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "corrected-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    print(type(val_idx), len(val_idx), val_idx.shape)\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    # Perform bagged model building and evaluation to get a score\n",
    "    print(val_dataset.num_data())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "functioning-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
    "    train_dataset.construct()\n",
    "    val_dataset.construct()\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def train_lgbm_model(config, train_dataset, val_dataset):\n",
    "        evals_result = {}\n",
    "        booster = lgb.train(config,\n",
    "                           train_dataset,\n",
    "                           valid_sets=[train_dataset, val_dataset],\n",
    "                           valid_names=['train', 'val'],\n",
    "                           evals_result=evals_result,\n",
    "                           feval=lgb_f1_micro,\n",
    "                           callbacks=[wandb_callback()])                           )\n",
    "        return booster, evals_result\n",
    "\n",
    "def eval_bagged_model(config, num_bags, train_dataset, val_dataset):\n",
    "    bagged_preds = np.zeros(val_dataset.num_data())\n",
    "    config = dict(config) # in case you input a wandb config object\n",
    "    for n in range(num_bags):\n",
    "        config['seed'] += n\n",
    "        booster, evals_result = train_lgbm_model(config, train_dataset,\n",
    "                                                val_dataset)\n",
    "        # Do I need to predict? Does the callback do it for me automatically?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accepting-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
    "    train_dataset.construct()\n",
    "    val_dataset.construct()\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def train_lgbm_model(config, train_dataset, val_dataset):\n",
    "        evals_result = {}\n",
    "        booster = lgb.train(config,\n",
    "                           train_dataset,\n",
    "                           valid_sets=[train_dataset, val_dataset],\n",
    "                           valid_names=['train', 'val'],\n",
    "                           evals_result=evals_result,\n",
    "                           feval=lgb_f1_micro,\n",
    "                           callbacks=[wandb_callback()])\n",
    "        return booster, evals_result\n",
    "\n",
    "def eval_bagged_model(config, num_bags, train_dataset, val_dataset):\n",
    "    bagged_preds = np.zeros(val_dataset.num_data())\n",
    "    config = dict(config) # in case you input a wandb config object\n",
    "    for n in range(num_bags):\n",
    "        config['seed'] += n\n",
    "        booster, evals_result = train_lgbm_model(config, train_dataset,\n",
    "                                                val_dataset)\n",
    "        # Do I need to predict? Does the callback do it for me automatically?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bigger-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
    "    train_dataset.construct()\n",
    "    val_dataset.construct()\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def train_lgbm_model(config, train_dataset, val_dataset):\n",
    "        evals_result = {}\n",
    "        booster = lgb.train(config,\n",
    "                           train_dataset,\n",
    "                           valid_sets=[train_dataset, val_dataset],\n",
    "                           valid_names=['train', 'val'],\n",
    "                           evals_result=evals_result,\n",
    "                           feval=lgb_f1_micro,\n",
    "                           callbacks=[wandb_callback()])\n",
    "        return booster, evals_result\n",
    "\n",
    "def eval_bagged_model(config, num_bags, train_dataset, val_dataset):\n",
    "    bagged_preds = np.zeros(val_dataset.num_data())\n",
    "    config = dict(config) # in case you input a wandb config object\n",
    "    for n in range(num_bags):\n",
    "        config['seed'] += n\n",
    "        booster, evals_result = train_lgbm_model(config, train_dataset,\n",
    "                                                val_dataset)\n",
    "        # Do I need to predict? Does the callback do it for me automatically?\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "crude-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path('../download')\n",
    "DATA_DIR = Path('../data')\n",
    "SUBMISSIONS_DIR = Path('../submissions')\n",
    "MODEL_DIR = Path('../models')\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / 'train_values.csv', index_col='building_id')\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "bool_columns = [col for col in X.columns if col.startswith('has')]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / 'test_values.csv', index_col='building_id')\n",
    "y = pd.read_csv(DOWNLOAD_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "russian-painting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">graceful-sponge-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/282kx404\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/282kx404</a><br/>\n",
       "                Run data is saved locally in <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210316_182441-282kx404</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_child_samples': 40,\n",
    "         'learning_rate': 0.03,\n",
    "         'num_boost_round': 40,\n",
    "         'early_stopping_rounds': 12,\n",
    "         'boosting_type': 'goss',\n",
    "         'objective': 'multiclassova',\n",
    "         'is_unbalance': True,\n",
    "         'metric': ['multiclassova', 'multi_error'],\n",
    "         'num_class': 3,\n",
    "         'verbosity': -1,\n",
    "         'num_threads': 8,\n",
    "         'seed': 1}\n",
    "\n",
    "run = wandb.init(project='earthquake_damage_competition',\n",
    "                 config=param)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "all_eval_results = {}\n",
    "all_boosters = {}\n",
    "# Cross-validation loop\n",
    "for i, train_idx, val_idx in enumerate(skf.split(X_all_ints, y)):\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    # Perform bagged model building and evaluation to get a score\n",
    "    booster, evals_results = train_lgbm_model(param, train_dataset,\n",
    "                                             val_dataset)\n",
    "    all_eval_results[i] = evals_results\n",
    "    all_boosters[i] = booster    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tracked-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_child_samples': 40,\n",
    "         'learning_rate': 0.03,\n",
    "         'num_boost_round': 40,\n",
    "         'early_stopping_rounds': 12,\n",
    "         'boosting_type': 'goss',\n",
    "         'objective': 'multiclassova',\n",
    "         'is_unbalance': True,\n",
    "         'metric': ['multiclassova', 'multi_error'],\n",
    "         'num_class': 3,\n",
    "         'verbosity': -1,\n",
    "         'num_threads': 8,\n",
    "         'seed': 1}\n",
    "\n",
    "run = wandb.init(project='earthquake_damage_competition',\n",
    "                 config=param)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "all_eval_results = {}\n",
    "all_boosters = {}\n",
    "i = 0\n",
    "# Cross-validation loop\n",
    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
    "                                                       train_idx, val_idx)\n",
    "    # Perform bagged model building and evaluation to get a score\n",
    "    booster, evals_results = train_lgbm_model(param, train_dataset,\n",
    "                                             val_dataset)\n",
    "    all_eval_results[i] = evals_results\n",
    "    all_boosters[i] = booster\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
