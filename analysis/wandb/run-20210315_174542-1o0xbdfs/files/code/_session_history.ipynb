{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lonely-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
    "DOWNLOAD_DIR = Path(\"../download\")\n",
    "DATA_DIR = Path(\"../data\")\n",
    "SUBMISSIONS_DIR = Path(\"../submissions\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "#######################################\n",
    "\n",
    "##### GOOGLE COLAB ######\n",
    "# DOWNLOAD_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/download')\n",
    "# SUBMISSIONS_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/submissions')\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/data')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/Work/Delivery/Current/earthquake_damage_competition/model')\n",
    "########################\n",
    "\n",
    "X = pd.read_csv(DOWNLOAD_DIR / \"train_values.csv\", index_col=\"building_id\")\n",
    "categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "bool_columns = [col for col in X.columns if col.startswith(\"has\")]\n",
    "\n",
    "X_test = pd.read_csv(DOWNLOAD_DIR / \"test_values.csv\", index_col=\"building_id\")\n",
    "y = pd.read_csv(DOWNLOAD_DIR / \"train_labels.csv\", index_col=\"building_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amended-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "particular-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imperial-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"earthquake_damage_competition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contained-messaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86868, 38)"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "focal-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "t = [(\"ord_encoder\", OrdinalEncoder(dtype=int), categorical_columns)]\n",
    "ct = ColumnTransformer(transformers=t, remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "respected-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_ints = ct.fit_transform(X)\n",
    "y = label_enc.fit_transform(np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effective-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that append for pandas objects works differently to append with\n",
    "# python objects e.g. python append modifes the list in-place\n",
    "# pandas append returns a new object, leaving the original unmodified\n",
    "not_categorical_columns = X.select_dtypes(exclude=\"object\").columns\n",
    "cols_ordered_after_ordinal_encoding = categorical_columns.append(\n",
    "    not_categorical_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approved-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = pd.Index([\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"])\n",
    "cat_cols_plus_geo = categorical_columns.append(geo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acting-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    X_all_ints,\n",
    "    label=y,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "material-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the docs for lgb.train and lgb.cv\n",
    "# Helpful Stackoverflow answer:\n",
    "# https://stackoverflow.com/questions/50931168/f1-score-metric-in-lightgbm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def get_ith_pred(preds, i, num_data, num_class):\n",
    "    \"\"\"\n",
    "    preds: 1D NumPY array\n",
    "        A 1D numpy array containing predicted probabilities. Has shape\n",
    "        (num_data * num_class,). So, For binary classification with\n",
    "        100 rows of data in your training set, preds is shape (200,),\n",
    "        i.e. (100 * 2,).\n",
    "    i: int\n",
    "        The row/sample in your training data you wish to calculate\n",
    "        the prediction for.\n",
    "    num_data: int\n",
    "        The number of rows/samples in your training data\n",
    "    num_class: int\n",
    "        The number of classes in your classification task.\n",
    "        Must be greater than 2.\n",
    "\n",
    "\n",
    "    LightGBM docs tell us that to get the probability of class 0 for\n",
    "    the 5th row of the dataset we do preds[0 * num_data + 5].\n",
    "    For class 1 prediction of 7th row, do preds[1 * num_data + 7].\n",
    "\n",
    "    sklearn's f1_score(y_true, y_pred) expects y_pred to be of the form\n",
    "    [0, 1, 1, 1, 1, 0...] and not probabilities.\n",
    "\n",
    "    This function translates preds into the form sklearn's f1_score\n",
    "    understands.\n",
    "    \"\"\"\n",
    "    # Does not work for binary classification, preds has a different form\n",
    "    # in that case\n",
    "    assert num_class > 2\n",
    "\n",
    "    preds_for_ith_row = [\n",
    "        preds[class_label * num_data + i] for class_label in range(num_class)\n",
    "    ]\n",
    "\n",
    "    # The element with the highest probability is predicted\n",
    "    return np.argmax(preds_for_ith_row)\n",
    "\n",
    "\n",
    "def lgb_f1_micro(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "\n",
    "    num_data = len(y_true)\n",
    "    num_class = 3\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(num_data):\n",
    "        ith_pred = get_ith_pred(preds, i, num_data, num_class)\n",
    "        y_pred.append(ith_pred)\n",
    "\n",
    "    return \"f1\", f1_score(y_true, y_pred, average=\"micro\"), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structured-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certified-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120, 'min_child_samples': 40, 'learning_rate': 0.1, 'boosting_type': 'goss', 'objective': 'multiclassova', 'is_unbalance': True, 'metric': ['multiclassova', 'multi_error'], 'num_class': 3, 'verbosity': -1, 'num_threads': 8, 'seed': 1}"
     ]
    }
   ],
   "source": [
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regional-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120, 'min_child_samples': 40, 'learning_rate': 0.1, 'boosting_type': 'goss', 'objective': 'multiclassova', 'is_unbalance': True, 'metric': ['multiclassova', 'multi_error'], 'num_class': 3, 'verbosity': -1, 'num_threads': 8, 'seed': 1}"
     ]
    }
   ],
   "source": [
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rough-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120, 'min_child_samples': 40, 'learning_rate': 0.1, 'boosting_type': 'goss', 'objective': 'multiclassova', 'is_unbalance': True, 'metric': ['multiclassova', 'multi_error'], 'num_class': 3, 'verbosity': -1, 'num_threads': 8, 'seed': 1}"
     ]
    }
   ],
   "source": [
    "run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unlimited-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    wandb.config,\n",
    "    train_data,\n",
    "    100,\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "velvet-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all_ints, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "full_train_data = lgb.Dataset(\n",
    "    X_all_ints,\n",
    "    label=y,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "armed-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all_ints, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "full_train_data = lgb.Dataset(\n",
    "    X_all_ints,\n",
    "    label=y,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    feature_name=list(cols_ordered_after_ordinal_encoding),\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "younger-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "experienced-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    wandb.config,\n",
    "    train_data,\n",
    "    100,\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "downtown-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120, 'min_child_samples': 40, 'learning_rate': 0.1, 'boosting_type': 'goss', 'objective': 'multiclassova', 'is_unbalance': True, 'metric': ['multiclassova', 'multi_error'], 'num_class': 3, 'verbosity': -1, 'num_threads': 8, 'seed': 1}"
     ]
    }
   ],
   "source": [
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "measured-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    }
   ],
   "source": [
    "wandb.config == param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collected-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120, 'min_child_samples': 40, 'learning_rate': 0.1, 'boosting_type': 'goss', 'objective': 'multiclassova', 'is_unbalance': True, 'metric': ['multiclassova', 'multi_error'], 'num_class': 3, 'verbosity': -1, 'num_threads': 8, 'seed': 1}"
     ]
    }
   ],
   "source": [
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hourly-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(wandb.config)\n",
    "pprint(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "entire-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    param,\n",
    "    train_data,\n",
    "    100,\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "disabled-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"f1\", title=\"F1 (micro) score for validation and training\"\n",
    ")\n",
    "wandb.log({\"f1_score plot\": wandb.Image(f1_plot)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "intermediate-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_plot = lgb.plot_metric(\n",
    "    evals_result,\n",
    "    metric=\"multi_logloss\",\n",
    "    title=\"Multi Log Loss for validation and training\",\n",
    ")\n",
    "wandb.log({\"multi logloss plot\": wandb.Image(log_loss_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "desperate-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "multierror_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"multi_error\", title=\"Multi Error for validation and training\"\n",
    ")\n",
    "wandb.log({\"multi error plot\": wandb.Image(multierror_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "overhead-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb.sdk.wandb_config.Config"
     ]
    }
   ],
   "source": [
    "type(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sticky-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb.sdk.wandb_config.Config"
     ]
    }
   ],
   "source": [
    "type(run.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "funny-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict"
     ]
    }
   ],
   "source": [
    "type(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "golden-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 120,\n",
      " 'min_child_samples': 40,\n",
      " 'learning_rate': 0.1,\n",
      " 'boosting_type': 'goss',\n",
      " 'objective': 'multiclassova',\n",
      " 'is_unbalance': True,\n",
      " 'metric': ['multiclassova', 'multi_error'],\n",
      " 'num_class': 3,\n",
      " 'verbosity': -1,\n",
      " 'num_threads': 8,\n",
      " 'seed': 1}"
     ]
    }
   ],
   "source": [
    "dict(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "weekly-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_boost_round\": 50,\n",
    "    \"early_stopping_round\": 5,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mysterious-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    dict(wandb.config),  # doesn't work if I pass wandb.config\n",
    "    train_data,\n",
    "    #                     100, # let's see if this works by setting it in param instead\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    #                     early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "entire-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"f1\", title=\"F1 (micro) score for validation and training\"\n",
    ")\n",
    "wandb.log({\"f1_score plot\": wandb.Image(f1_plot)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "presidential-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_plot = lgb.plot_metric(\n",
    "    evals_result,\n",
    "    metric=\"multi_logloss\",\n",
    "    title=\"Multi Log Loss for validation and training\",\n",
    ")\n",
    "wandb.log({\"multi logloss plot\": wandb.Image(log_loss_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "similar-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "multierror_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"multi_error\", title=\"Multi Error for validation and training\"\n",
    ")\n",
    "wandb.log({\"multi error plot\": wandb.Image(multierror_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "closed-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_boost_round\": 50,\n",
    "    \"early_stopping_round\": 5,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "favorite-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    dict(wandb.config),  # doesn't work if I pass wandb.config\n",
    "    train_data,\n",
    "    #                     100, # let's see if this works by setting it in param instead\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    #                     early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "conventional-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"f1\", title=\"F1 (micro) score for validation and training\"\n",
    ")\n",
    "wandb.log({\"f1_score plot\": wandb.Image(f1_plot)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "compliant-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_plot = lgb.plot_metric(\n",
    "    evals_result,\n",
    "    metric=\"multi_logloss\",\n",
    "    title=\"Multi Log Loss for validation and training\",\n",
    ")\n",
    "wandb.log({\"multi logloss plot\": wandb.Image(log_loss_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spanish-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "multierror_plot = lgb.plot_metric(\n",
    "    evals_result, metric=\"multi_error\", title=\"Multi Error for validation and training\"\n",
    ")\n",
    "wandb.log({\"multi error plot\": wandb.Image(multierror_plot)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "southern-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_boost_round\": 40,\n",
    "    \"early_stopping_round\": -1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "blessed-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    dict(wandb.config),  # doesn't work if I pass wandb.config\n",
    "    train_data,\n",
    "    #                     100, # let's see if this works by setting it in param instead\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    #                     early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "senior-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:27n9do9f) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21399<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faabe2de42e1421bbb41c50377ae3cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1.87MB of 1.87MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210315_174438-27n9do9f/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210315_174438-27n9do9f/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_multi_logloss</td><td>0.78638</td></tr><tr><td>train_multi_error</td><td>0.43109</td></tr><tr><td>train_f1</td><td>0.56891</td></tr><tr><td>val_multi_logloss</td><td>0.7918</td></tr><tr><td>val_multi_error</td><td>0.43109</td></tr><tr><td>val_f1</td><td>0.56891</td></tr><tr><td>_step</td><td>14</td></tr><tr><td>_runtime</td><td>36</td></tr><tr><td>_timestamp</td><td>1615823120</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_multi_logloss</td><td>█▇▇▆▆▅▄▄▄▃▃▂▂▁▁</td></tr><tr><td>train_multi_error</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_multi_logloss</td><td>█▇▇▆▆▅▄▄▄▃▃▂▂▁▁</td></tr><tr><td>val_multi_error</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>_runtime</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wobbly-violet-8</strong>: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/27n9do9f\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/27n9do9f</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:27n9do9f). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">swept-sun-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/1o0xbdfs\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/1o0xbdfs</a><br/>\n",
       "                Run data is saved locally in <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210315_174542-1o0xbdfs</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_boost_round\": 40,\n",
    "    \"early_stopping_round\": -1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "peripheral-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "evals_result = {}\n",
    "booster = lgb.train(\n",
    "    dict(wandb.config),  # doesn't work if I pass wandb.config\n",
    "    train_data,\n",
    "    #                     100, # let's see if this works by setting it in param instead\n",
    "    # You can include train_data in the valid_set to easily\n",
    "    # make plots of the loss functions\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    evals_result=evals_result,\n",
    "    #                     early_stopping_rounds=None,\n",
    "    categorical_feature=list(cat_cols_plus_geo),\n",
    "    feval=lgb_f1_micro,\n",
    "    callbacks=[wandb_callback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accompanied-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\": 120,\n",
    "    \"min_child_samples\": 40,\n",
    "    \"learning_rate\": 0.04,\n",
    "    \"num_boost_round\": 40,\n",
    "    \"early_stopping_round\": -1,\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"objective\": \"multiclassova\",\n",
    "    \"is_unbalance\": True,\n",
    "    \"metric\": [\"multiclassova\", \"multi_error\"],\n",
    "    \"num_class\": 3,\n",
    "    \"verbosity\": -1,\n",
    "    \"num_threads\": 8,\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "run = wandb.init(project=\"earthquake_damage_competition\", config=param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
