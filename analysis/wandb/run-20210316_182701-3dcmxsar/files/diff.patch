diff --git a/analysis/bagging.ipynb b/analysis/bagging.ipynb
index f9628e4..dc22fa9 100644
--- a/analysis/bagging.ipynb
+++ b/analysis/bagging.ipynb
@@ -50,12 +50,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 31,
    "id": "anonymous-savannah",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:07.314289Z",
-     "start_time": "2021-03-15T15:24:04.121919Z"
+     "end_time": "2021-03-16T16:21:53.349254Z",
+     "start_time": "2021-03-16T16:21:52.455303Z"
     },
     "executionInfo": {
      "elapsed": 2001,
@@ -81,6 +81,8 @@
     "import pickle\n",
     "from pathlib import Path\n",
     "from tqdm.notebook import trange, tqdm\n",
+    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
+    "from wandb.lightgbm import wandb_callback\n",
     "\n",
     "### USE FOR LOCAL JUPYTER NOTEBOOKS ###\n",
     "DOWNLOAD_DIR = Path('../download')\n",
@@ -106,12 +108,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 14,
    "id": "boxed-upper",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:07.512273Z",
-     "start_time": "2021-03-15T15:24:07.509191Z"
+     "end_time": "2021-03-16T15:09:47.403655Z",
+     "start_time": "2021-03-16T15:09:47.400451Z"
     }
    },
    "outputs": [],
@@ -544,8 +546,8 @@
    "id": "determined-library",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:13.810793Z",
-     "start_time": "2021-03-15T15:24:12.232620Z"
+     "end_time": "2021-03-16T14:54:55.919121Z",
+     "start_time": "2021-03-16T14:54:52.739507Z"
     },
     "id": "determined-library",
     "outputId": "420f632a-92fb-4c29-c91a-826eaa443af9",
@@ -621,12 +623,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 4,
    "id": "documentary-victoria",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:19.676054Z",
-     "start_time": "2021-03-15T15:24:19.671433Z"
+     "end_time": "2021-03-16T14:54:59.013301Z",
+     "start_time": "2021-03-16T14:54:59.009186Z"
     },
     "id": "documentary-victoria",
     "outputId": "023863ce-fc30-4800-bff8-17a5b793b0d8"
@@ -638,7 +640,7 @@
        "(86868, 38)"
       ]
      },
-     "execution_count": 5,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -649,12 +651,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 15,
    "id": "stock-companion",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:19.818633Z",
-     "start_time": "2021-03-15T15:24:19.804052Z"
+     "end_time": "2021-03-16T15:09:54.893621Z",
+     "start_time": "2021-03-16T15:09:54.890312Z"
     },
     "executionInfo": {
      "elapsed": 587,
@@ -682,12 +684,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 16,
    "id": "brief-karma",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:20.494575Z",
-     "start_time": "2021-03-15T15:24:19.962861Z"
+     "end_time": "2021-03-16T15:09:55.941871Z",
+     "start_time": "2021-03-16T15:09:55.485804Z"
     },
     "executionInfo": {
      "elapsed": 830,
@@ -710,12 +712,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 17,
    "id": "possible-neighbor",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:20.704068Z",
-     "start_time": "2021-03-15T15:24:20.663235Z"
+     "end_time": "2021-03-16T15:09:56.529575Z",
+     "start_time": "2021-03-16T15:09:56.490300Z"
     },
     "executionInfo": {
      "elapsed": 517,
@@ -741,12 +743,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 18,
    "id": "confidential-elimination",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:20.862876Z",
-     "start_time": "2021-03-15T15:24:20.859200Z"
+     "end_time": "2021-03-16T15:09:57.211712Z",
+     "start_time": "2021-03-16T15:09:57.209143Z"
     },
     "executionInfo": {
      "elapsed": 559,
@@ -769,12 +771,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 19,
    "id": "adaptive-dietary",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:23.530270Z",
-     "start_time": "2021-03-15T15:24:23.527237Z"
+     "end_time": "2021-03-16T15:09:58.481654Z",
+     "start_time": "2021-03-16T15:09:58.478934Z"
     },
     "executionInfo": {
      "elapsed": 414,
@@ -799,12 +801,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 20,
    "id": "judicial-error",
    "metadata": {
     "ExecuteTime": {
-     "end_time": "2021-03-15T15:24:24.063026Z",
-     "start_time": "2021-03-15T15:24:24.056677Z"
+     "end_time": "2021-03-16T15:09:59.804910Z",
+     "start_time": "2021-03-16T15:09:59.800581Z"
     },
     "executionInfo": {
      "elapsed": 569,
@@ -2083,7 +2085,7 @@
     "id": "addressed-discovery"
    },
    "source": [
-    "## Validating Bagged Models\n",
+    "## Bagged Models with WandB\n",
     "\n",
     "Let's build one model first and see how we can interact with it. I want to get some plots to see how we can use validation data. But using the LGBM API is SO MUCH BETTER than using the sklearn API for LightGBM, so let's play with this and see what happens."
    ]
@@ -2107,31 +2109,23 @@
     "\n",
     "full_train_data = lgb.Dataset(X_all_ints,\n",
     "                             label=y,\n",
-    "                             feature_name=list(cols_ordered_after_ordinal_encoding),\n",
-    "                             categorical_feature=list(cat_cols_plus_geo),\n",
+    "#                              feature_name=list(cols_ordered_after_ordinal_encoding),\n",
+    "#                              categorical_feature=list(cat_cols_plus_geo),\n",
     "                             free_raw_data=False)\n",
     "\n",
     "train_data = lgb.Dataset(X_train,\n",
     "                        label=y_train,\n",
-    "                        feature_name=list(cols_ordered_after_ordinal_encoding),\n",
-    "                        categorical_feature=list(cat_cols_plus_geo),\n",
+    "#                         feature_name=list(cols_ordered_after_ordinal_encoding),\n",
+    "#                         categorical_feature=list(cat_cols_plus_geo),\n",
     "                        free_raw_data=False)\n",
     "\n",
     "val_data = lgb.Dataset(X_val,\n",
     "                      label=y_val,\n",
-    "                      feature_name=list(cols_ordered_after_ordinal_encoding),\n",
-    "                      categorical_feature=list(cat_cols_plus_geo),\n",
+    "#                       feature_name=list(cols_ordered_after_ordinal_encoding),\n",
+    "#                       categorical_feature=list(cat_cols_plus_geo),\n",
     "                      free_raw_data=False)"
    ]
   },
-  {
-   "cell_type": "markdown",
-   "id": "devoted-pipeline",
-   "metadata": {},
-   "source": [
-    "### DO I NEED TO SET CATEGORICAL_FEATURE AND FEATURE_NAME IN LGB.TRAIN IF I HAVE SET THEM IN THE LGB.DATASET OBJECT?"
-   ]
-  },
   {
    "cell_type": "code",
    "execution_count": 62,
@@ -2306,7 +2300,7 @@
     "         'min_child_samples': 40,\n",
     "         'learning_rate': 0.03,\n",
     "         'num_boost_round': 40,\n",
-    "         'early_stopping_round': -1,\n",
+    "         'early_stopping_rounds': 12,\n",
     "         'boosting_type': 'goss',\n",
     "         'objective': 'multiclassova',\n",
     "         'is_unbalance': True,\n",
@@ -2390,8 +2384,6 @@
     }
    ],
    "source": [
-    "from wandb.lightgbm import wandb_callback\n",
-    "\n",
     "evals_result = {}\n",
     "booster = lgb.train(dict(wandb.config), # doesn't work if I pass wandb.config\n",
     "                    train_data,\n",
@@ -2403,6 +2395,7 @@
     "                    evals_result=evals_result,\n",
     "#                     early_stopping_rounds=None,\n",
     "                    categorical_feature=list(cat_cols_plus_geo),\n",
+    "                    feature_name=list(cols_ordered_after_ordinal_encoding)\n",
     "                    feval=lgb_f1_micro,\n",
     "                    callbacks=[wandb_callback()])"
    ]
@@ -2617,12 +2610,318 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "agricultural-longer",
+   "cell_type": "markdown",
+   "id": "oriental-brazilian",
    "metadata": {
     "id": "agricultural-longer"
    },
+   "source": [
+    "## Validating Bagged Models"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 30,
+   "id": "alternative-train",
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2021-03-16T16:19:55.824807Z",
+     "start_time": "2021-03-16T16:19:55.819537Z"
+    },
+    "code_folding": []
+   },
+   "outputs": [],
+   "source": [
+    "def get_train_val_datasets(X, y, train_idx, val_idx):\n",
+    "    X_train, X_val = X[train_idx], X[val_idx]\n",
+    "    y_train, y_val = y[train_idx], y[val_idx]\n",
+    "    \n",
+    "    train_dataset = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
+    "    val_dataset = lgb.Dataset(X_val, label=y_val, free_raw_data=False)\n",
+    "    train_dataset.construct()\n",
+    "    val_dataset.construct()\n",
+    "    return train_dataset, val_dataset\n",
+    "\n",
+    "\n",
+    "def train_lgbm_model(config, train_dataset, val_dataset):\n",
+    "        evals_result = {}\n",
+    "        booster = lgb.train(config,\n",
+    "                           train_dataset,\n",
+    "                           valid_sets=[train_dataset, val_dataset],\n",
+    "                           valid_names=['train', 'val'],\n",
+    "                           evals_result=evals_result,\n",
+    "                           feval=lgb_f1_micro,\n",
+    "                           callbacks=[wandb_callback()])\n",
+    "        return booster, evals_result\n",
+    "\n",
+    "def eval_bagged_model(config, num_bags, train_dataset, val_dataset):\n",
+    "    bagged_preds = np.zeros(val_dataset.num_data())\n",
+    "    config = dict(config) # in case you input a wandb config object\n",
+    "    for n in range(num_bags):\n",
+    "        config['seed'] += n\n",
+    "        booster, evals_result = train_lgbm_model(config, train_dataset,\n",
+    "                                                val_dataset)\n",
+    "        # Do I need to predict? Does the callback do it for me automatically?\n",
+    "        pass"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 33,
+   "id": "split-asthma",
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2021-03-16T16:25:32.858931Z",
+     "start_time": "2021-03-16T16:25:22.871725Z"
+    }
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/html": [
+       "Finishing last run (ID:282kx404) before initializing another..."
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "<br/>Waiting for W&B process to finish, PID 41173<br/>Program ended successfully."
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value=' 0.01MB of 0.01MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Find user logs for this run at: <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210316_182441-282kx404/logs/debug.log</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Find internal logs for this run at: <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210316_182441-282kx404/logs/debug-internal.log</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                    <br/>Synced <strong style=\"color:#cdcd00\">graceful-sponge-14</strong>: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/282kx404\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/282kx404</a><br/>\n",
+       "                "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "...Successfully finished last run (ID:282kx404). Initializing new run:<br/><br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.22 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "                Tracking run with wandb version 0.10.20<br/>\n",
+       "                Syncing run <strong style=\"color:#cdcd00\">worldly-pyramid-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
+       "                Project page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition</a><br/>\n",
+       "                Run page: <a href=\"https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/1rmefeon\" target=\"_blank\">https://wandb.ai/theadammurphy/earthquake_damage_competition/runs/1rmefeon</a><br/>\n",
+       "                Run data is saved locally in <code>/Users/king/Google Drive/Work/Delivery/Current/earthquake_damage_competition/analysis/wandb/run-20210316_182522-1rmefeon</code><br/><br/>\n",
+       "            "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "ename": "KeyError",
+     "evalue": "\"None of [Int64Index([     0,      1,      2,      3,      4,      5,      7,      8,\\n                11,     12,\\n            ...\\n            260589, 260590, 260591, 260592, 260593, 260594, 260595, 260596,\\n            260597, 260600],\\n           dtype='int64', length=208480)] are in the [columns]\"",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-33-0bf3c1a7770a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all_ints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n\u001b[0;32m---> 26\u001b[0;31m                                                        train_idx, val_idx)\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Perform bagged model building and evaluation to get a score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     booster, evals_results = train_lgbm_model(param, train_dataset,\n",
+      "\u001b[0;32m<ipython-input-30-580f081ec688>\u001b[0m in \u001b[0;36mget_train_val_datasets\u001b[0;34m(X, y, train_idx, val_idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_train_val_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/opt/anaconda3/envs/tabular/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/opt/anaconda3/envs/tabular/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/opt/anaconda3/envs/tabular/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([     0,      1,      2,      3,      4,      5,      7,      8,\\n                11,     12,\\n            ...\\n            260589, 260590, 260591, 260592, 260593, 260594, 260595, 260596,\\n            260597, 260600],\\n           dtype='int64', length=208480)] are in the [columns]\""
+     ]
+    }
+   ],
+   "source": [
+    "param = {'num_leaves': 120,\n",
+    "         'min_child_samples': 40,\n",
+    "         'learning_rate': 0.03,\n",
+    "         'num_boost_round': 40,\n",
+    "         'early_stopping_rounds': 12,\n",
+    "         'boosting_type': 'goss',\n",
+    "         'objective': 'multiclassova',\n",
+    "         'is_unbalance': True,\n",
+    "         'metric': ['multiclassova', 'multi_error'],\n",
+    "         'num_class': 3,\n",
+    "         'verbosity': -1,\n",
+    "         'num_threads': 8,\n",
+    "         'seed': 1}\n",
+    "\n",
+    "run = wandb.init(project='earthquake_damage_competition',\n",
+    "                 config=param)\n",
+    "\n",
+    "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
+    "\n",
+    "all_eval_results = {}\n",
+    "all_boosters = {}\n",
+    "i = 0\n",
+    "# Cross-validation loop\n",
+    "for train_idx, val_idx in skf.split(X_all_ints, y):\n",
+    "    train_dataset, val_dataset = get_train_val_datasets(X_all_ints, y,\n",
+    "                                                       train_idx, val_idx)\n",
+    "    # Perform bagged model building and evaluation to get a score\n",
+    "    booster, evals_results = train_lgbm_model(param, train_dataset,\n",
+    "                                             val_dataset)\n",
+    "    all_eval_results[i] = evals_results\n",
+    "    all_boosters[i] = booster\n",
+    "    i += 1"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "assisted-repeat",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "compatible-marathon",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "hired-brother",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "grand-timothy",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "controlling-grocery",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "hundred-oliver",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "nasty-lancaster",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "sunrise-welsh",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "narrow-uruguay",
+   "metadata": {},
    "outputs": [],
    "source": []
   },
diff --git a/analysis/wandb/latest-run b/analysis/wandb/latest-run
index c3f2a32..4ef79d0 120000
--- a/analysis/wandb/latest-run
+++ b/analysis/wandb/latest-run
@@ -1 +1 @@
-run-20210315_175036-2yj128hh
\ No newline at end of file
+run-20210316_182701-3dcmxsar
\ No newline at end of file
